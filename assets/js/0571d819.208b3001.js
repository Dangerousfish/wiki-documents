"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[42944],{15680:(e,t,i)=>{i.d(t,{xA:()=>d,yg:()=>m});var n=i(96540);function o(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function r(e,t){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),i.push.apply(i,n)}return i}function a(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{};t%2?r(Object(i),!0).forEach((function(t){o(e,t,i[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):r(Object(i)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(i,t))}))}return e}function s(e,t){if(null==e)return{};var i,n,o=function(e,t){if(null==e)return{};var i,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)i=r[n],t.indexOf(i)>=0||(o[i]=e[i]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)i=r[n],t.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(o[i]=e[i])}return o}var c=n.createContext({}),l=function(e){var t=n.useContext(c),i=t;return e&&(i="function"==typeof e?e(t):a(a({},t),e)),i},d=function(e){var t=l(e.components);return n.createElement(c.Provider,{value:t},e.children)},g="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var i=e.components,o=e.mdxType,r=e.originalType,c=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),g=l(i),u=o,m=g["".concat(c,".").concat(u)]||g[u]||p[u]||r;return i?n.createElement(m,a(a({ref:t},d),{},{components:i})):n.createElement(m,a({ref:t},d))}));function m(e,t){var i=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=i.length,a=new Array(r);a[0]=u;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[g]="string"==typeof e?e:o,a[1]=s;for(var l=2;l<r;l++)a[l]=i[l];return n.createElement.apply(null,a)}return n.createElement.apply(null,i)}u.displayName="MDXCreateElement"},85111:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>l});var n=i(9668),o=(i(96540),i(15680));const r={description:"How to use Training(Object Detection)",title:"Object Detection",image:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/1.9.png",slug:"/sensecraft_ai_Training_Object_Detection",sidebar_position:2,last_update:{date:"11/27/2024",author:"qiuyu wei"}},a="Type of training - Object Detection",s={unversionedId:"Cloud_Chain/SenseCraft/SenseCraft_AI/Training/Object_Detection",id:"Cloud_Chain/SenseCraft/SenseCraft_AI/Training/Object_Detection",title:"Object Detection",description:"How to use Training(Object Detection)",source:"@site/docs/Cloud_Chain/SenseCraft/SenseCraft_AI/Training/Object_Detection.md",sourceDirName:"Cloud_Chain/SenseCraft/SenseCraft_AI/Training",slug:"/sensecraft_ai_Training_Object_Detection",permalink:"/sensecraft_ai_Training_Object_Detection",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Cloud_Chain/SenseCraft/SenseCraft_AI/Training/Object_Detection.md",tags:[],version:"current",lastUpdatedBy:"qiuyu wei",lastUpdatedAt:1732665600,formattedLastUpdatedAt:"Nov 27, 2024",sidebarPosition:2,frontMatter:{description:"How to use Training(Object Detection)",title:"Object Detection",image:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/1.9.png",slug:"/sensecraft_ai_Training_Object_Detection",sidebar_position:2,last_update:{date:"11/27/2024",author:"qiuyu wei"}},sidebar:"ProductSidebar",previous:{title:"Classification",permalink:"/sensecraft_ai_Training_Classification"},next:{title:"Grove Vision AI v2 Workspace on SenseCraft AI Platform",permalink:"/grove_vision_ai_v2_workspace"}},c={},l=[{value:"Features of object detection",id:"features-of-object-detection",level:2},{value:"Quick Training",id:"quick-training",level:2},{value:"Step",id:"step",level:3},{value:"Demonstration of results",id:"demonstration-of-results",level:3},{value:"Image Collection Training",id:"image-collection-training",level:2},{value:"Step",id:"step-1",level:3},{value:"Demonstration of results",id:"demonstration-of-results-1",level:3},{value:"Tech Support &amp; Product Discussion",id:"tech-support--product-discussion",level:2}],d={toc:l},g="wrapper";function p(e){let{components:t,...i}=e;return(0,o.yg)(g,(0,n.A)({},d,i,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("h1",{id:"type-of-training---object-detection"},"Type of training - Object Detection"),(0,o.yg)("h2",{id:"features-of-object-detection"},"Features of object detection"),(0,o.yg)("p",null,"The Seeed SenseCraft AI Platform is an efficient AI training tool tailored for object detection tasks. Built on the advanced ",(0,o.yg)("strong",{parentName:"p"},"YOLO - World object detection model"),", it offers two convenient training methods:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Quick Training"),"\nFeatures: No image data is required. Simply input the target name to quickly generate a single-class object detection model.\nAdvantages: Ideal for straightforward scenarios, enabling fast model creation and deployment."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Image Collection Training"),"\nFeatures: Combines the target name with uploaded image data for training.\nAdvantages: Leverages diverse image data to significantly improve the detection accuracy of the generated model, making it suitable for applications requiring high precision.\nWith these two methods, the SenseCraft platform caters to diverse object detection model training needs, simplifying the complexities of AI development while ensuring both usability and precision.",(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/2.0.png",style:{width:750,height:"auto"}})))),(0,o.yg)("h2",{id:"quick-training"},"Quick Training"),(0,o.yg)("p",null,"We will create a simple demo for ",(0,o.yg)("strong",{parentName:"p"},"recognising human"),'. The quick training feature leverages the following core characteristics of the YOLO \u2013 World object detection model:\nThe quick training feature uses YOLO\u2019s strengths to efficiently create single-class detection models. By combining pretrained weights, text semantics, and efficient feature extraction, it generates a tailored model, such as for "human", without requiring image data.'),(0,o.yg)("h3",{id:"step"},"Step"),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 1:")," Enter the target name in the text box. Then click on ",(0,o.yg)("strong",{parentName:"p"},"'Start Training'"),"."),(0,o.yg)("admonition",{type:"tip"},(0,o.yg)("p",{parentName:"admonition"},"The training session will last 1-3 minutes, so please be patient!")),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/2.1.png",style:{width:800,height:"auto"}})),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 2.")," After completing the model training, the model will be deployed and Grove Vision AI (V2) will be selected for the deployment. Then choose the correct serial port to connect to, and finally wait patiently for 1-3 minutes to know that the model training is complete!"),(0,o.yg)("admonition",{type:"caution"},(0,o.yg)("p",{parentName:"admonition"},"Device selection in Object Detection can only support ",(0,o.yg)("strong",{parentName:"p"},"Grove Vision AI (V2)"),".")),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/2.2.png",style:{width:800,height:"auto"}})),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/2.3.png",style:{width:800,height:"auto"}})),(0,o.yg)("h3",{id:"demonstration-of-results"},"Demonstration of results"),(0,o.yg)("p",null,"After completing the above steps, the model will be successfully deployed and run, but care needs to be taken with the ",(0,o.yg)("strong",{parentName:"p"},"Confidence Threshold")," and ",(0,o.yg)("strong",{parentName:"p"},"IoU Threshold value")," settings, which will affect the model's ability to recognise."),(0,o.yg)("admonition",{type:"tip"},(0,o.yg)("p",{parentName:"admonition"},(0,o.yg)("strong",{parentName:"p"},"Confidence Threshold:")," The minimum confidence score a model must have to consider a detection valid, filtering out low-confidence predictions.\n",(0,o.yg)("strong",{parentName:"p"},"IoU Threshold:")," The minimum Intersection over Union (IoU) value required to classify a predicted bounding box as a true positive, ensuring accuracy in overlap measurement between predicted and ground truth boxes.")),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/2.4.png",style:{width:800,height:"auto"}})),(0,o.yg)("h2",{id:"image-collection-training"},"Image Collection Training"),(0,o.yg)("p",null,"We'll make a demo that ",(0,o.yg)("strong",{parentName:"p"},"recognises earphones"),". Based on YOLO \u2013 World object detection model, you can customize the training for text and image, which can improve the detection accuracy of the generated model."),(0,o.yg)("h3",{id:"step-1"},"Step"),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 3.")," First enter the target name in the text box and then select ",(0,o.yg)("strong",{parentName:"p"},"Grove Vision AI (V2)")," to connect."),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/3.2.png",style:{width:800,height:"auto"}})),(0,o.yg)("admonition",{type:"tip"},(0,o.yg)("p",{parentName:"admonition"},"If the connection is successful, a live preview of the camera will appear in the box on the right.")),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/3.3.png",style:{width:800,height:"auto"}})),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 4.")," Then point the camera at the target object and click ",(0,o.yg)("strong",{parentName:"p"},"'Capture'"),", then box the target object with a red box and finally click ",(0,o.yg)("strong",{parentName:"p"},"'Confirm'"),"."),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/3.4.png",style:{width:800,height:"auto"}})),(0,o.yg)("admonition",{type:"tip"},(0,o.yg)("p",{parentName:"admonition"},"The more image material, the better the recognition of model.")),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 5.")," Click on ",(0,o.yg)("strong",{parentName:"p"},"'Training'")," and then wait patiently for the model to finish training."),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/3.5.png",style:{width:800,height:"auto"}})),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 6.")," And finally it's time for model deployment."),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/3.6.png",style:{width:800,height:"auto"}})),(0,o.yg)("h3",{id:"demonstration-of-results-1"},"Demonstration of results"),(0,o.yg)("p",null,"Once the above steps are completed, the model will be successfully trained and deployed."),(0,o.yg)("div",{style:{textAlign:"center"}},(0,o.yg)("img",{src:"https://files.seeedstudio.com/wiki/SenseCraft_AI/img3/object%20detection/3.7.gif",style:{width:800,height:"auto"}})),(0,o.yg)("h2",{id:"tech-support--product-discussion"},"Tech Support & Product Discussion"),(0,o.yg)("p",null,"Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs."),(0,o.yg)("div",{class:"button_tech_support_container"},(0,o.yg)("a",{href:"https://forum.seeedstudio.com/",class:"button_forum"}),(0,o.yg)("a",{href:"https://www.seeedstudio.com/contacts",class:"button_email"})),(0,o.yg)("div",{class:"button_tech_support_container"},(0,o.yg)("a",{href:"https://discord.gg/eWkprNDMU7",class:"button_discord"}),(0,o.yg)("a",{href:"https://github.com/Seeed-Studio/wiki-documents/discussions/69",class:"button_discussion"})))}p.isMDXComponent=!0}}]);