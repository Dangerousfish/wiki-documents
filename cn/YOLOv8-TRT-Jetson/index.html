<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-zh-CN/Edge/NVIDIA_Jetson/Application/Computer_Vision/YOLOv8-TRT-Jetson" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">在NVIDIA Jetson上使用TensorRT部署YOLOv8 | Seeed Studio Wiki</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://wiki.seeedstudio.com/cn/YOLOv8-TRT-Jetson/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="在NVIDIA Jetson上使用TensorRT部署YOLOv8 | Seeed Studio Wiki"><meta data-rh="true" name="description" content="在NVIDIA Jetson上使用TensorRT部署YOLOv8"><meta data-rh="true" property="og:description" content="在NVIDIA Jetson上使用TensorRT部署YOLOv8"><meta data-rh="true" property="og:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><meta data-rh="true" name="twitter:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><link data-rh="true" rel="icon" href="/img/S.png"><link data-rh="true" rel="canonical" href="https://wiki.seeedstudio.com/cn/YOLOv8-TRT-Jetson/"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/cn/YOLOv8-TRT-Jetson/" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/cn/YOLOv8-TRT-Jetson/" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Seeed Studio Wiki RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Seeed Studio Wiki Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-M4JG2HVB",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>


<link rel="icon" href="/img/S.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37, 194, 160)">


<link rel="search" type="application/opensearchdescription+xml" title="Seeed Studio Wiki" href="/opensearch.xml">
<script src="https://viewer.altium.com/client/static/js/embed.js" async></script>
<script src="/js/custom.js" async></script><link rel="stylesheet" href="/assets/css/styles.82713764.css">
<link rel="preload" href="/assets/js/runtime~main.7c471d29.js" as="script">
<link rel="preload" href="/assets/js/main.82b0c6ef.js" as="script">
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-M4JG2HVB" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#013949;color:#FFFFFF" role="banner"><div class="content_knG7 announcementBarContent_xLdY">Collaborating with us! Join the Seeed Studio <a target="_blank" href="https://wiki.seeedstudio.com/ranger/">Ranger Program</a> or <a target="_blank" href="https://wiki.seeedstudio.com/contributors/">Contributor Program</a>!</div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="https://files.seeedstudio.com/wiki/wiki-platform/SeeedStudio.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--light_HNdA navbar_logo_items"><img src="https://files.seeedstudio.com/wiki/wiki-platform/seeed_white_logo.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--dark_i4oU navbar_logo_items"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items js_getting_started" aria-haspopup="true" aria-expanded="false" role="button" href="/Getting_Started/">Quick Links</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Sensor_Network/">Sensor and Sensing</a></li><li><a class="dropdown__link" href="/Network/">Networking</a></li><li><a class="dropdown__link" href="/Edge_Computing/">Edge Computing</a></li><li><a class="dropdown__link" href="/Cloud/">Cloud</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items js_explore_learn" aria-haspopup="true" aria-expanded="false" role="button" href="/topicintroduction/">Explore with Topics</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tinyml_topic/">TinyML</a></li><li><a class="dropdown__link" href="/ModelAssistant_Introduce_Overview/">SenseCraft Model Assistant</a></li><li><a class="dropdown__link" href="/home_assistant_topic/">Home Assistant</a></li><li><a class="dropdown__link" href="/open_source_topic/">Open Source</a></li><li><a class="dropdown__link" href="/edge_ai_topic/">Edge AI</a></li><li><a class="dropdown__link" href="/cn/Getting_Started/">矽递科技 Wiki 文档平台</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/knowledgebase/">FAQs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Jetson_FAQ/">NVIDIA Jetson Series</a></li><li><a class="dropdown__link" href="/XIAO_FAQ/">Seeed Studio XIAO Series</a></li><li><a class="dropdown__link" href="/reComputer_R1000_FAQ/">reComputer R1000 Series</a></li><li><a class="dropdown__link" href="/reTerminal-new_FAQ/">reTerminal</a></li><li><a class="dropdown__link" href="/FAQs_For_openWrt/">reRouter</a></li><li><a class="dropdown__link" href="/ODYSSEY_FAQ/">Odyssey</a></li><li><a class="dropdown__link" href="/wio_terminal_faq/">Wio Terminal</a></li><li><hr style="margin: 8px 0;"></li><li><a href="https://discord.com/invite/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="dropdown__link">Discord<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="dropdown__link">Email<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Forum<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="dropdown__link">Have Suggestions?<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/ranger/">Rangers</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/ranger/">Rangers</a></li><li><a class="dropdown__link" href="/contributors/">Contributors</a></li><li><a href="https://docs.google.com/forms/d/e/1FAIpQLSdiAWHmRJqgVNTJyJDkzhufc1dygFyhWFyEtUTm-mrgSKaEgg/viewform" target="_blank" rel="noopener noreferrer" class="dropdown__link">Apply for Rangers<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/orgs/Seeed-Studio/projects/6" target="_blank" rel="noopener noreferrer" class="dropdown__link">Direct to Assignments<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.seeedstudio.com/blog/2023/09/15/join-the-seeed-ranger-program-empowering-developers-and-building-communities/" target="_blank" rel="noopener noreferrer" class="dropdown__link">More about Rangers<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://wiki.seeedstudio.com/Contributor" target="_blank" rel="noopener noreferrer" class="dropdown__link">More about Contributors<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">Bazaar 🛍️</a><a href="https://wiki-gpt.seeedstudio.com/chat" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">AI Bot 🤖️</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">SenseCraft AI</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-SSCMA"></a><a href="https://github.com/Seeed-Studio/wiki-documents" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Getting_Started/">矽递科技 Wiki 文档平台</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/Grove_System/">Grove 系列</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/grove_vision_ai_v2/">Grove 传感器</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/Grove_Accessories_Intro/">Grove 配件</a><button aria-label="Toggle the collapsible sidebar category &#x27;Grove 配件&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/SeeedStudio_XIAO_Series_Introduction/">XIAO 拇指开发板</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/Seeeduino-XIAO/">XIAO SAMD21</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO SAMD21&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/XIAO-RP2040/">XIAO RP2040</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO RP2040&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/XIAO_BLE/">XIAO nRF52840 (Sense)</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO nRF52840 (Sense)&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/XIAO_ESP32C3_Getting_Started/">XIAO ESP32C3</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO ESP32C3&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/xiao_esp32s3_getting_started/">XIAO ESP32S3 (Sense)</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO ESP32S3 (Sense)&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/get_start_round_display/">XIAO 的兼容扩展板</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/XIAO-Kit-Courses/">基于 XIAO 的初学者套件</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/xiao_topic_page/">XIAO 系列教程和项目合集</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/XIAO_FAQ/">XIAO 开发板常见问题</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/reComputer_Intro/">NVIDIA Jetson 套件</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/reComputer_Intro/">reComputer 英伟达系列</a><button aria-label="Toggle the collapsible sidebar category &#x27;reComputer 英伟达系列&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/Generative_AI_Intro/">生成式人工智能应用</a><button aria-label="Toggle the collapsible sidebar category &#x27;生成式人工智能应用&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/cn/How_to_Train_and_Deploy_YOLOv8_on_reComputer/">计算机视觉应用</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/How_to_Train_and_Deploy_YOLOv8_on_reComputer/">如何在reComputer上训练和部署YOLOv8</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/Jetson-Nano-MaskCam/">口罩相机 - 基于Jetson Nano的人群口罩使用监测</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/Security_Scan/">刀具检测：基于reComputer部署在Triton推理服务器上的物体检测模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/reComputer_Jetson_Series_Projects/">英伟达 Jetson 官方项目</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/Traffic-Management-DeepStream-SDK/">基于 DeepStream SDK的智能交通管理系统</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/YOLOv5-Object-Detection-Jetson/">使用YOLOv5和Roboflow进行少样本目标检测</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/YOLOv8-DeepStream-TRT-Jetson/">在NVIDIA Jetson上使用TensorRT和DeepStream SDK部署YOLOv8</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/cn/YOLOv8-TRT-Jetson/">在NVIDIA Jetson上使用TensorRT部署YOLOv8</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/train_and_deploy_a_custom_classification_model_with_yolov8/">使用 YOLOv8 训练和部署自定义分类模型</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/Wio_Terminal_Intro/">Wio Terminal</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Wio-Terminal-Getting-Started-test/">Wio Terminal入门教程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Wio-Terminal-CircuitPython/">Wio Terminal上的CircuitPython</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Software-FreeRTOS/">Wio Terminal上的FreeRTOS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/wio_terminal_faq/">Wio Terminal 常见问题解答</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Wio-Terminal-LCD-Overview/">硬件概述</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Connect-Wio-Terminal-to-Microsoft-Azure-IoT-Central/">应用</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Wio-Terminal-Battery-Chassis/">扩展板</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Wio-Terminal-TinyML-Kit-Course/">课程套件</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Wio-Terminal-Firmware/">教程</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/Quantum-Mini-Linux-Development-Kit/">夸克(Quark)迷你开发者套件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/mmwave_radar_Intro/">毫米波雷达传感器</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/mmwave_for_xiao/">用于XIAO的毫米波</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/mmwave_human_detection_kit/">毫米波套件</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR24BSD1/">24GHz 毫米波传感器 - 睡眠呼吸监测</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR24FDB1/">24GHz毫米波传感器 - 人体跌倒检测传感器</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR24HPB1/">24GHz 毫米波传感器 - 人体静态存在模块</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR24HPC1/">24GHz毫米波传感器 - 人体静态存在模块精简版</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR60BHA1/">60GHz毫米波传感器 - 人体静态睡眠呼吸监测</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR60FDA1/">60GHz毫米波传感器 - 跌倒检测模块专业版</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_z5aJ"><div class="docItemContainer_c0TR"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">计算机视觉应用</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">在NVIDIA Jetson上使用TensorRT部署YOLOv8</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>在NVIDIA Jetson上使用TensorRT部署YOLOv8</h1><p>这篇维基指南解释了如何将YOLOv8模型部署到NVIDIA Jetson平台，并使用TensorRT进行推理。在这里，我们使用TensorRT来最大化Jetson平台上的推理性能。</p><p>这里将介绍不同的计算机视觉任务，包括：</p><ul><li>目标检测</li><li>图像分割</li><li>图像分类</li><li>姿态估计</li><li>目标跟踪</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/8.gif" style="width:1000px;height:auto" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="先决条件">先决条件<a href="#先决条件" class="hash-link" aria-label="Direct link to 先决条件" title="Direct link to 先决条件">​</a></h2><ul><li>Ubuntu 主机 PC 系统安装或使用VMware Workstation Player的虚拟机</li><li><a href="https://www.seeedstudio.com/reComputer-J4012-p-5586.html" target="_blank" rel="noopener noreferrer">reComputer Jetson</a> 任何其他运行 JetPack 5.1.1 或更高版本的 NVIDIA Jetson 设备</li></ul><p>:::注意
此 wiki 已在 <a href="https://www.seeedstudio.com/reComputer-J4012-p-5586.html" target="_blank" rel="noopener noreferrer">reComputer J4012</a> 和 <a href="https://www.seeedstudio.com/reComputer-Industrial-J4012-p-5684.html" target="_blank" rel="noopener noreferrer">reComputer Industrial J4012</a> 上进行测试并验证，该设备由 NVIDIA Jetson 或 NX 16GB 模块驱动
:::</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="刷写-jetpack-到-jetson">刷写 JetPack 到 Jetson<a href="#刷写-jetpack-到-jetson" class="hash-link" aria-label="Direct link to 刷写 JetPack 到 Jetson" title="Direct link to 刷写 JetPack 到 Jetson">​</a></h2><p>现在您需要确保 Jetson 设备已刷写 <a href="https://developer.nvidia.com/embedded/jetpack" target="_blank" rel="noopener noreferrer">JetPack</a> 系统。您可以使用 NVIDIA SDK Manager 或命令行来刷写 JetPack 到设备。</p><p>对于 Seeed Jetson 驱动设备的刷写指南，请参考以下链接：</p><ul><li><a href="https://wiki.seeedstudio.com/reComputer_J1010_J101_Flash_Jetpack" target="_blank" rel="noopener noreferrer">reComputer J1010 | J101</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_J2021_J202_Flash_Jetpack" target="_blank" rel="noopener noreferrer">reComputer J2021 | J202</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_J1020_A206_Flash_JetPack" target="_blank" rel="noopener noreferrer">reComputer J1020 | A206</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_J4012_Flash_Jetpack" target="_blank" rel="noopener noreferrer">reComputer J4012 | J401</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_A203_Flash_System" target="_blank" rel="noopener noreferrer">A203 Carrier Board</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_A205_Flash_System" target="_blank" rel="noopener noreferrer">A205 Carrier Board</a></li><li><a href="https://wiki.seeedstudio.com/Jetson_Xavier_AGX_H01_Driver_Installation" target="_blank" rel="noopener noreferrer">Jetson Xavier AGX H01 Kit</a></li><li><a href="https://wiki.seeedstudio.com/Jetson_AGX_Orin_32GB_H01_Flash_Jetpack" target="_blank" rel="noopener noreferrer">Jetson AGX Orin 32GB H01 Kit</a></li></ul><p>:::注意
请确保刷写 JetPack 版本 5.1.1，因为这是我们在本 wiki 中验证过的版本
:::</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="一行代码将-yolov8-部署到-jetson">一行代码将 YOLOv8 部署到 Jetson！<a href="#一行代码将-yolov8-部署到-jetson" class="hash-link" aria-label="Direct link to 一行代码将 YOLOv8 部署到 Jetson！" title="Direct link to 一行代码将 YOLOv8 部署到 Jetson！">​</a></h2><p>在您将 Jetson 设备刷写 JetPack 系统后，您可以简单地运行以下命令来运行 YOLOv8 模型。这将首先下载并安装必要的包、依赖项，设置环境，并从 YOLOv8 下载预训练模型以执行对象检测、图像分割、姿态估计和图像分类任务！</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget files.seeedstudio.com/YOLOv8-Jetson.py &amp;&amp; python YOLOv8-Jetson.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>:::注意
上述脚本的源代码可以在此找到。<a href="https://github.com/yuyoujiang/Run-YOLOv8-in-One-Line-on-Jetson" target="_blank" rel="noopener noreferrer">here</a>
:::</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="使用预训练模型">使用预训练模型<a href="#使用预训练模型" class="hash-link" aria-label="Direct link to 使用预训练模型" title="Direct link to 使用预训练模型">​</a></h2><p>开始使用 YOLOv8 的最快方式是使用 YOLOv8 提供的预训练模型。然而，这些是 PyTorch 模型，因此在 Jetson 上进行推理时将仅利用 CPU。如果您希望在 Jetson 上运行 GPU 时获得这些模型的最佳性能，可以通过遵循本 wiki 的这一部分将 PyTorch 模型导出到 TensorRT。</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import Tabs from &#x27;@theme/Tabs&#x27;;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import TabItem from &#x27;@theme/TabItem&#x27;;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div><div value="detec" label="Object Detection"><p>YOLOv8 提供了 5 种针对对象检测任务的预训练 PyTorch 模型权重，这些模型是在 COCO 数据集上训练的，输入图像尺寸为 640x640。</p><table><thead><tr><th>模型</th><th>尺寸<br>(像素)</th><th>mAPval<br>50-95</th><th>CPU ONNX<br>速度<br>(ms)</th><th>A100 TensorRT<br>速度<br>(ms)</th><th>参数<br>(M)</th><th>FLOPs<br>(B)</th></tr></thead><tbody><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt" target="_blank" rel="noopener noreferrer">YOLOv8n</a></td><td>640</td><td>37.3</td><td>80.4</td><td>0.99</td><td>3.2</td><td>8.7</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt" target="_blank" rel="noopener noreferrer">YOLOv8s</a></td><td>640</td><td>44.9</td><td>128.4</td><td>1.20</td><td>11.2</td><td>28.6</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt" target="_blank" rel="noopener noreferrer">YOLOv8m</a></td><td>640</td><td>50.2</td><td>234.7</td><td>1.83</td><td>25.9</td><td>78.9</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt" target="_blank" rel="noopener noreferrer">YOLOv8l</a></td><td>640</td><td>52.9</td><td>375.2</td><td>2.39</td><td>43.7</td><td>165.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt" target="_blank" rel="noopener noreferrer">YOLOv8x</a></td><td>640</td><td>53.9</td><td>479.1</td><td>3.53</td><td>68.2</td><td>257.8</td></tr></tbody></table><p>参考: <a href="https://docs.ultralytics.com/tasks/detect" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/tasks/detect</a></p><p>您可以选择并从上表下载您所需的模型，然后执行以下命令在图像上进行推理。</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=yolov8n.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>在这里，对于模型，您可以更改为 yolov8s.pt、yolov8m.pt、yolov8l.pt 或 yolov8x.pt 中的任何一个，它将下载相应的预训练模型。</p><p>您还可以连接一个网络摄像头，并执行以下命令。</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=yolov8n.pt source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>:::注意
如果在执行上述命令时遇到任何错误，请尝试在命令的末尾添加 &quot;device=0&quot;。
:::</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/2.gif" style="width:1000px;height:auto" class="img_ev3q"></div><p>:::注意
上述操作是在 reComputer J4012 或 reComputer Industrial J4012 上运行的，并使用经过 640x640 输入尺寸训练的 YOLOv8s 模型，并采用 TensorRT FP16 精度。
:::</p></div><div value="classfiy" label="Image Classification"><p>YOLOv8 提供了 5 种针对图像分类任务的预训练 PyTorch 模型权重，这些模型是在 ImageNet 数据集上训练的，输入图像尺寸为 224x224。您可以在下面找到它们。</p><table><thead><tr><th>模型</th><th>尺寸<br>(像素)</th><th>acc<br>top1</th><th>acc<br>top5<br></th><th>CPU ONNX<br>速度<br>(ms)<br></th><th>A100 TensorRT<br>速度<br>(ms)<br><br></th><th>参数<br>(M)<br></th><th>FLOPs<br>(B) at 640</th></tr></thead><tbody><tr><td>YOLOv8n-cls</td><td>224</td><td>66.6</td><td>87.0</td><td>12.9</td><td>0.31</td><td>2.7</td><td>4.3</td></tr><tr><td>YOLOv8s-cls</td><td>224</td><td>72.3</td><td>91.1</td><td>23.4</td><td>0.35</td><td>6.4</td><td>13.5</td></tr><tr><td>YOLOv8m-cls</td><td>224</td><td>76.4</td><td>93.2</td><td>85.4</td><td>0.62</td><td>17.0</td><td>42.7</td></tr><tr><td>YOLOv8l-cls</td><td>224</td><td>78.0</td><td>94.1</td><td>163.0</td><td>0.87</td><td>37.5</td><td>99.7</td></tr><tr><td> YOLOv8x-cls</td><td>224</td><td>78.4</td><td>94.3</td><td>232.0</td><td>1.01</td><td>57.4</td><td>154.8</td></tr></tbody></table><p>参考: <a href="https://docs.ultralytics.com/tasks/classify" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/tasks/classify</a></p><p>您可以选择您想要的模型，并执行以下命令在图像上运行推理。</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo classify predict model=yolov8n-cls.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>在这里，对于模型，您可以更改为 yolov8s-cls.pt、yolov8m-cls.pt、yolov8l-cls.pt 或 yolov8x-cls.pt 中的任何一个，它将下载相应的预训练模型。</p><p>您还可以连接一个网络摄像头，并执行以下命令。</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo classify predict model=yolov8n-cls.pt source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>:::注意
如果您在执行上述命令时遇到任何错误，请尝试在命令的末尾添加&quot;device=0&quot;。
:::</p><p>(更新为 224 像素推理。)</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/5.gif" style="width:1000px;height:auto" class="img_ev3q"></div><p>:::注意
上述操作是在 reComputer J4012 或 reComputer Industrial J4012 上运行的，并使用经过 224x224 输入尺寸训练的 YOLOv8s-cls 模型，并采用 TensorRT FP16 精度。同时，在使用 TensorRT 导出的模型时，请确保在推理命令中传递参数 <strong>imgsz=224</strong>，因为推理引擎默认接受 640 像素的图像尺寸。
:::</p></div><div value="segment" label="Image Segmentation"><p>YOLOv8 提供了 5 种针对图像分割任务的预训练 PyTorch 模型权重，这些模型是在 COCO 数据集上训练的，输入图像尺寸为 640x640。您可以在下面找到它们：</p><table><thead><tr><th>模型</th><th>尺寸<br>(像素)</th><th>mAPbox<br>50-95</th><th>mAPmask<br>50-95</th><th>CPU ONNX<br>速度<br>(ms)</th><th>A100 TensorRT<br>速度<br>(ms)</th><th>参数<br>(M)</th><th>FLOPs<br>(B)</th></tr></thead><tbody><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8n-seg</a></td><td>640</td><td>36.7</td><td>30.5</td><td>96.1</td><td>1.21</td><td>3.4</td><td>12.6</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8s-seg</a></td><td>640</td><td>44.6</td><td>36.8</td><td>155.7</td><td>1.47</td><td>11.8</td><td>42.6</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8m-seg</a></td><td>640</td><td>49.9</td><td>40.8</td><td>317.0</td><td>2.18</td><td>27.3</td><td>110.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8l-seg</a></td><td>640</td><td>52.3</td><td>42.6</td><td>572.4</td><td>2.79</td><td>46.0</td><td>220.5</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8x-seg</a></td><td>640</td><td>53.4</td><td>43.4</td><td>712.1</td><td>4.02</td><td>71.8</td><td>344.1</td></tr></tbody></table><p>参考: <a href="https://docs.ultralytics.com/tasks/segment" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/tasks/segment</a></p><p>您可以选择您想要的模型，并执行以下命令在图像上运行推理</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo segment predict model=yolov8n-seg.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>在这里，对于模型，您可以更改为 yolov8s.pt、yolov8m.pt、yolov8l.pt 或 yolov8x.pt 中的任何一个，它将下载相应的预训练模型。</p><p>您还可以连接一个网络摄像头，并执行以下命令。</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo segment predict model=yolov8n-seg.pt source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>:::注意
如果您在执行上述命令时遇到任何错误，请尝试在命令的末尾添加 &quot;device=0&quot;。
:::</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/3.gif" style="width:1000px;height:auto" class="img_ev3q"></div><p>:::注意
上述操作是在 reComputer J4012 或 reComputer Industrial J4012 上运行的，并使用经过 640x640 输入尺寸训练的 YOLOv8s-seg 模型，并采用 TensorRT FP16 精度。
:::</p></div><div value="pose" label="Pose Estimation"><p>YOLOv8 提供了 6 种针对姿态估计任务的预训练 PyTorch 模型权重，这些模型是在 COCO 关键点数据集上训练的，输入图像尺寸为 640x640。您可以在下面找到它们：</p><table><thead><tr><th>模型</th><th>尺寸<br>(像素)</th><th>mAPpose<br>50-95</th><th>mAPpose<br>50</th><th>CPU ONNX<br>速度<br>(ms)</th><th>A100 TensorRT<br>速度<br>(ms)</th><th>参数<br>(M)</th><th>FLOPs<br>(B)</th></tr></thead><tbody><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8n-pose</a></td><td>640</td><td>50.4</td><td>80.1</td><td>131.8</td><td>1.18</td><td>3.3</td><td>9.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8s-pose</a></td><td>640</td><td>60.0</td><td>86.2</td><td>233.2</td><td>1.42</td><td>11.6</td><td>30.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8m-pose</a></td><td>640</td><td>65.0</td><td>88.8</td><td>456.3</td><td>2.00</td><td>26.4</td><td>81.0</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8l-pose</a></td><td>640</td><td>67.6</td><td>90.0</td><td>784.5</td><td>2.59</td><td>44.4</td><td>168.6</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8x-pose</a></td><td>640</td><td>69.2</td><td>90.2</td><td>1607.1</td><td>3.73</td><td>69.4</td><td>263.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-pose-p6.pt" target="_blank" rel="noopener noreferrer">YOLOv8x-pose-p6</a></td><td>1280</td><td>71.6</td><td>91.2</td><td>4088.7</td><td>10.04</td><td>99.1</td><td>1066.4</td></tr></tbody></table><p>参考: <a href="https://docs.ultralytics.com/tasks/pose" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/tasks/pose</a></p><p>选择您所需的模型后，您可以执行以下命令来对图像进行推理：</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo pose predict model=yolov8n-pose.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>在这里，对于模型，您可以更改为 yolov8s.pt、yolov8m.pt、yolov8l.pt 或 yolov8x.pt 中的任何一个，它将下载相应的预训练模型。</p><p>您还可以连接一个网络摄像头，并执行以下命令。 </p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo pose predict model=yolov8n-pose.pt source=&#x27;0&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>:::注意
如果您在执行上述命令时遇到任何错误，请尝试在命令的末尾添加&quot;device=0&quot;。
:::</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/4.gif" style="width:1000px;height:auto" class="img_ev3q"></div></div><div value="track" label="Object Tracking"><p>对象跟踪是一项涉及识别视频中对象的位置和类别，然后为该检测分配一个唯一 ID 的任务。</p><p>基本上，对象跟踪的输出与对象检测相同，只是增加了对象 ID。</p><p>参考: <a href="https://docs.ultralytics.com/modes/track" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/modes/track</a></p><p>您可以选择基于对象检测或图像分割的所需模型，并执行以下命令在视频上运行推理：</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo track model=yolov8n.pt source=&quot;https://youtu.be/Zgi9g1ksQHc&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>在这里，对于模型，您可以更改为 yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt, yolov8n-seg.pt, yolov8s-seg.pt, yolov8m-seg.pt, yolov8l-seg.pt, yolov8x-seg.pt 中的任何一个，它将下载相应的预训练模型。</p><p>您还可以连接一个网络摄像头，并执行以下命令。 </p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo track model=yolov8n.pt source=&quot;0&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>:::注意
如果您在执行上述命令时遇到任何错误，请尝试在命令的末尾添加 &quot;device=0&quot;。
:::</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/6.gif" style="width:1000px;height:auto" class="img_ev3q"></div><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/7.gif" style="width:1000px;height:auto" class="img_ev3q"></div></div></div><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="使用-tensorrt-提高推理速度">使用 TensorRT 提高推理速度<a href="#使用-tensorrt-提高推理速度" class="hash-link" aria-label="Direct link to 使用 TensorRT 提高推理速度" title="Direct link to 使用 TensorRT 提高推理速度">​</a></h2><p>正如我们之前提到的，如果您想要提高在 Jetson 上运行 YOLOv8 模型的推理速度，您首先需要将原始的 PyTorch 模型转换为 TensorRT 模型。</p><p>按照以下步骤将 YOLOv8 PyTorch 模型转换为 TensorRT 模型。</p><p>:::注意
这对我们之前提到的所有四种计算机视觉任务都有效
:::</p><ul><li><strong>步骤 1.</strong> 执行导出命令时，请指定模型路径。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo export model=&lt;path_to_pt_file&gt; format=engine device=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>例如:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo export model=yolov8n.pt format=engine device=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>:::注意
如果您遇到有关 cmake 的错误，您可以忽略它。请耐心等待 TensorRT 导出完成。这可能需要几分钟时间。
:::</p><p>TensorRT 模型文件 (.engine) 创建完成后，您将看到如下输出：</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/1.jpg" style="width:800px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 2.</strong>
如果您想要传递额外的参数，您可以通过以下表格进行：</li></ul><table><thead><tr><th>Key</th><th>Value</th><th>Description</th></tr></thead><tbody><tr><td>imgsz</td><td>640</td><td>Image size as scalar or (h, w) list, i.e. (640, 480)</td></tr><tr><td>half</td><td>False</td><td>FP16 quantization</td></tr><tr><td>dynamic</td><td>False</td><td>Dynamic axes</td></tr><tr><td>simplify</td><td>False</td><td>Simplify model</td></tr><tr><td>workspace</td><td>4</td><td>Workspace size (GB)</td></tr></tbody></table><p>例如，如果您想要将您的 PyTorch 模型转换为 FP16 量化的 TensorRT 模型，请执行以下命令：</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo export model=yolov8n.pt format=engine half=True device=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>一旦模型成功导出，您可以在运行 4 项任务（检测、分类、分割、姿态估计）时，在 <strong>yolo</strong> 的 <strong>predict</strong> 命令中使用 <strong>model=</strong> 参数替换此模型。以下是如何执行此操作的示例：</p><p>例如, 在目标检测中:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=yolov8n.engine source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="使用自己的ai模型">使用自己的AI模型<a href="#使用自己的ai模型" class="hash-link" aria-label="Direct link to 使用自己的AI模型" title="Direct link to 使用自己的AI模型">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="数据收集和标注">数据收集和标注<a href="#数据收集和标注" class="hash-link" aria-label="Direct link to 数据收集和标注" title="Direct link to 数据收集和标注">​</a></h3><p>如果您有特定的 AI 应用，并希望使用适合您应用的自带 AI 模型，您可以收集自己的数据集，对它们进行标注，然后使用 YOLOv8 进行训练。 </p><p>如果您不想自己收集数据，您也可以选择已经准备好的公共数据集。您可以下载许多公开可用的数据集，例如 <a href="https://cocodataset.org" target="_blank" rel="noopener noreferrer">COCO dataset</a>, <a href="http://host.robots.ox.ac.uk/pascal/VOC" target="_blank" rel="noopener noreferrer">Pascal VOC dataset</a>等。<a href="https://universe.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Universe</a> 是一个十分好用的平台，它提供了广泛的数据集，拥有超过<a href="https://blog.roboflow.com/computer-vision-datasets-and-apis" target="_blank" rel="noopener noreferrer">90,000+ datasets with 66+ million images</a>  个数据集和 66+ 百万图像，适用于构建计算机视觉模型。此外，您也可以简单地在 Google 上搜索开源数据集，并从可用的多种数据集中进行选择。</p><p>如果您有自己的数据集并希望对图像进行标注，我们建议您使用<a href="https://roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow</a>提供的标注工具。 请按照 <a href="https://wiki.seeedstudio.com/YOLOv5-Object-Detection-Jetson/#annotate-dataset-using-roboflow" target="_blank" rel="noopener noreferrer">这里</a> 了解更多信息。您也可以遵循 <a href="https://docs.roboflow.com/annotate/use-roboflow-annotate" target="_blank" rel="noopener noreferrer">本指引</a> 学习标注</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="训练">训练<a href="#训练" class="hash-link" aria-label="Direct link to 训练" title="Direct link to 训练">​</a></h3><p>这里我们有三种训练模型的方法。</p><ol><li><p>第一种方法是使用 <a href="https://ultralytics.com/hub" target="_blank" rel="noopener noreferrer">Ultralytics HUB</a>。您可以轻松地将 Roboflow 集成到 Ultralytics HUB 中，这样您所有的 Roboflow 项目都将随时可用于训练。这里它提供了一个 Google Colab 笔记本，以便您轻松开始训练过程，并且还可以实时查看训练进度。</p></li><li><p>第二种方法是使用我们创建的 Google Colab 工作区来简化训练过程。在这里，我们使用 Roboflow API 从 Roboflow 项目下载数据集。</p></li><li><p>第三种方法是使用本地 PC 进行训练过程。在这里，您需要确保您拥有足够强大的 GPU，并且还需要手动下载数据集。</p></li></ol><div><div value="Ultralytics" label="Ultralytics HUB + Roboflow + Google Colab"><p>在这里，我们使用 Ultralytics HUB 加载 Roboflow 项目，然后在 Google Colab 上进行训练。</p><ul><li><p><strong>步骤 1.</strong> 访问 <a href="https://hub.ultralytics.com/signup" target="_blank" rel="noopener noreferrer">此网站</a> 并注册一个 Ultralytics 账户。</p></li><li><p><strong>步骤 2.</strong> 当您使用新创建的账户登录后，您将看到如下控制面板。</p></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/2.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><p><strong>步骤 3.</strong> 访问<a href="https://app.roboflow.com/login" target="_blank" rel="noopener noreferrer">此网站</a> ，并注册一个 Roboflow 账户。</p></li><li><p><strong>步骤 4.</strong> 当您使用新创建的账户登录后，您将看到如下控制面板。</p></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/11.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><p><strong>步骤 5.</strong> 创建一个新的工作区，并根据我们为您准备的<a href="https://wiki.seeedstudio.com/YOLOv5-Object-Detection-Jetson/#annotate-dataset-using-roboflow" target="_blank" rel="noopener noreferrer">维基指南</a>，在工作区内创建一个新项目。您也可以<a href="https://blog.roboflow.com/getting-started-with-roboflow" target="_blank" rel="noopener noreferrer">点击这里</a>，从官方的 Roboflow 文档中了解更多信息。</p></li><li><p><strong>步骤 6.</strong> 一旦您在工作区内创建了几个项目，界面将如下所示：</p></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/12.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 7.</strong> 前往 <strong>Settings</strong> 并点击 <strong>Roboflow API</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/13.jpg" style="width:300px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 8.</strong> 点击 <strong>copy</strong> 按钮以复制 <strong>Private API Key</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/14.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 9.</strong> 返回到 Ultralytics HUB 的仪表板，点击 <strong>集成（Integrations）</strong>，将我们之前复制的 API 密钥粘贴到空列中，然后点击 <strong>添加（Add）</strong>。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/15.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 10</strong> 如果您看到您的工作空间名称被列出，这意味着集成已成功。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/16.jpg" style="width:550px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 11</strong> 转到 <strong>数据集（Datasets）</strong>页面，您将在这里看到您所有的 Roboflow 项目。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/17.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 12</strong> 点击一个项目以查看有关数据集的更多信息。在这里，我选择了一个能够检测健康和损坏苹果的数据集。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/18.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 13</strong> 点击 <strong>Train Model</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/19.jpg" style="width:500px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 14</strong> 选择<strong>架构</strong>，设置<strong>模型名称（可选）</strong>，然后点击<strong>继续</strong>。在这里，我们选择了YOLOv8s作为模型架构。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/22.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 15</strong> 在<strong>高级选项</strong>下，根据你的偏好配置设置，复制并粘贴Colab代码（这将在稍后粘贴到Colab工作区），然后点击打开<strong>Google Colab</strong>。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/24.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 16</strong> 如果你还没有登录你的Google账户，请登录。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/25.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 17</strong> 导航至 <code>Runtime &gt; Change runtime type</code></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/26.jpg" style="width:500px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 18</strong> 在<strong>硬件加速器</strong>下选择<strong>GPU</strong>，然后选择<strong>GPU类型</strong>中可用的最高选项，并点击<strong>保存</strong>。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/27.jpg" style="width:500px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 19</strong> 点击 <strong>Connect</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/28.jpg" style="width:250px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 20</strong> 点击<strong>RAM, Disk</strong>按钮来检查硬件资源的使用情况。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/31.jpg" style="width:600px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 21</strong> 点击<strong>Play按钮</strong>来运行第一个代码单元。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/29.jpg" style="width:750px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 22</strong> 将我们之前从Ultralytics HUB复制的代码单元粘贴在<strong>开始</strong>部分下面，并运行它以开始训练。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/30.jpg" style="width:650px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 23</strong> 现在，如果你返回到Ultralytics HUB，你会看到<strong>已连接</strong>的消息。点击<strong>完成</strong>。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/32.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 24</strong> 在这里，你将实时看到模型在Google Colab上训练时的<strong>边框损失(Box Loss)、类别损失(Class Loss)和目标损失(Object Loss)</strong>。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/33.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 25</strong> 训练完成后，你将在Google Colab上看到以下输出：</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/34.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 26</strong> 现在返回到Ultralytics HUB，转到<strong>预览</strong>标签页，上传一张测试图片来检查训练好的模型的表现如何。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/35.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 27</strong> 最后，转到<strong>部署</strong>标签页，并下载你选择格式的训练好的模型，以便使用YOLOv8进行推理。在这里，我们选择了PyTorch格式。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/36.png" style="width:1000px;height:auto" class="img_ev3q"></div><p>现在，你可以使用这个下载的模型来执行我们在本维基中之前解释过的任务。你只需要将模型文件替换为你自己的模型即可。</p><p>例如:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=&lt;your_model.pt&gt; source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><div value="Roboflow" label="Roboflow + Google Colab"><p>在这里，我们使用Google Colaboratory环境在云端进行训练。此外，我们在Colab中使用Roboflow API轻松下载我们的数据集。</p><ul><li><strong>步骤 1.</strong> 点击 <a href="https://colab.research.google.com/gist/lakshanthad/9fbe33058cb7cab49ac8fc345143d849/yolov5-training-for-jetson.ipynb" target="_blank" rel="noopener noreferrer">这里</a> 打开一个已经准备好的Google Colab工作区并按照工作区中提到的步骤进行操作</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/39.jpg" style="width:800px;height:auto" class="img_ev3q"></div><p>在训练完成后，你将会看到如下的输出信息：</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/40.jpg" style="width:800px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 2.</strong> 在Google Colab的&quot;文件&quot;(File)标签页下，如果你导航到路径 <code>runs/train/exp/weights</code>，你会看到一个名为<strong>best.pt</strong>的文件。这个文件是训练过程中生成的最佳模型权重。你需要下载这个文件，然后将其复制到你的Jetson设备上，因为你稍后将在Jetson设备上使用这个模型进行推理。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/41.jpg" style="width:500px;height:auto" class="img_ev3q"></div><p>现在，你可以使用这个下载的模型来执行我们在本维基之前解释过的任务。你只需要将模型文件替换为你自己的模型。</p><p>例如:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=&lt;your_model.pt&gt; source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><div value="PC" label="Roboflow + Local PC"><p>在这里，你可以使用装有Linux操作系统的电脑进行训练。我们在这个维基中使用了Ubuntu 20.04操作系统的电脑。</p><ul><li><strong>步骤 1.</strong> 如果你的系统中没有安装pip，你可以按照以下步骤在Linux系统上安装它：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install python3-pip -y</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 2.</strong> 安装Ultralytics及其依赖项。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install ultralytics</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 3.</strong> 在Roboflow上，在您的项目中，转到<strong>版本(Versions)</strong>，选择<strong>导出数据集(Export Dataset)</strong>，选择<strong>格式</strong>为<strong>YOLOv8</strong>，选择<strong>下载zip到电脑(download zip to computer)</strong>，然后点击<strong>继续(Continue)</strong>。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/42.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><p><strong>步骤 4.</strong> 解压下载的 zip 文件</p></li><li><p><strong>步骤 5.</strong> 执行以下命令以开始训练。在这里，你需要将<strong>path_to_yaml</strong>替换为解压后的zip文件中.yaml文件的位置。</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo train data=&lt;path_to_yaml&gt; model=yolov8s.pt epochs=100 imgsz=640 batch=-1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>:::注意
这里图像尺寸被设置为640x640像素。我们使用批量大小（batch-size）为-1，这将自动确定最佳的批量大小。你也可以根据你的偏好更改训练周期（epoch）。在这里，你可以将预训练模型更改为任何检测（detect）、分割（segment）、分类（classify）、姿态（pose）模型。
:::</p><p>训练完成后，你会看到以下类型的输出：</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/43.png" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>步骤 6.</strong> 在目录 <strong>runs/detect/train/weights</strong> 下，你会看到一个名为 <strong>best.pt</strong> 的文件。这是训练过程中生成的最佳模型。你需要下载这个文件，并将其复制到你的Jetson设备上，因为稍后将使用这个模型在Jetson设备上进行推理。</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/44.png" style="width:500px;height:auto" class="img_ev3q"></div><p>现在，你可以使用这个下载的模型来执行我们在本维基之前解释过的任务。你只需要将模型文件替换为你自己的模型。</p><p>例如:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=&lt;your_model.pt&gt; source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="性能基准测试">性能基准测试<a href="#性能基准测试" class="hash-link" aria-label="Direct link to 性能基准测试" title="Direct link to 性能基准测试">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="准备">准备<a href="#准备" class="hash-link" aria-label="Direct link to 准备" title="Direct link to 准备">​</a></h3><p>我们已经对所有由YOLOv8支持的计算机视觉任务进行了性能基准测试，这些任务在搭载NVIDIA Jetson Orin NX 16GB模块的reComputer J4012或reComputer Industrial J4012上运行。</p><p>在样本目录中包含了一个名为<a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#trtexec" target="_blank" rel="noopener noreferrer">trtexec</a>的命令行包装工具。trtexec是一个使用TensorRT而无需开发自己的应用程序的工具。trtexec工具有三个主要目的：</p><ul><li>在随机或用户提供的输入数据上对网络进行基准测试。</li><li>从模型生成序列化引擎。</li><li>从构建器生成序列化的时序缓存。</li></ul><p>在这里，我们可以使用trtexec工具快速对不同参数的模型进行基准测试。但首先，你需要有一个ONNX模型，我们可以通过使用Ultralytics YOLOv8来生成这个ONNX模型。</p><ul><li><strong>步骤 1.</strong> 构建 ONNX 模型:</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo mode=export model=yolov8s.pt format=onnx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 2.</strong> 使用trtexec构建引擎文件的步骤如下：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /usr/src/tensorrt/bin</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">./trtexec --onnx=&lt;path_to_onnx_file&gt; --saveEngine=&lt;path_to_save_engine_file&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>例如:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./trtexec --onnx=/home/nvidia/yolov8s.onnx --saveEngine=/home/nvidia/yolov8s.engine</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>这样做将输出以下性能结果，同时会生成一个.engine文件。默认情况下，它会将ONNX转换为FP32精度下优化的TensorRT文件，你可以按照以下方式查看输出结果：</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/46.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><p>如果您希望使用<strong>FP16精度</strong>，它比<strong>FP32</strong>提供更好的性能，您可以按照以下方式执行上述命令：</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./trtexec --onnx=/home/nvidia/yolov8s.onnx --fp16 --saveEngine=/home/nvidia/yolov8s.engine </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>如果您希望使用<strong>INT8</strong>精度，它比<strong>FP16</strong>带来更好的性能，您可以按照以下方式执行上面的命令：</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./trtexec --onnx=/home/nvidia/yolov8s.onnx --int8 --saveEngine=/home/nvidia/yolov8s.engine </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="结果">结果<a href="#结果" class="hash-link" aria-label="Direct link to 结果" title="Direct link to 结果">​</a></h3><p>以下我们总结了在reComputer J4012和reComputer Industrial J4012上运行的所有四个计算机视觉任务的结果。</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/45.png" style="width:1000px;height:auto" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="额外演示使用yolov8进行运动检测和计数器">额外演示：使用YOLOv8进行运动检测和计数器。<a href="#额外演示使用yolov8进行运动检测和计数器" class="hash-link" aria-label="Direct link to 额外演示：使用YOLOv8进行运动检测和计数器。" title="Direct link to 额外演示：使用YOLOv8进行运动检测和计数器。">​</a></h2><p>我们已经构建了一个使用YOLOv8-Pose模型进行运动检测和计数的人体姿态估计演示应用程序。你可以访问<a href="https://github.com/yuyoujiang/Exercise-Counter-with-YOLOv8-on-NVIDIA-Jetson" target="_blank" rel="noopener noreferrer">项目页面e</a>来了解更多关于这个演示的信息，并将其部署到你自己的Jetson设备上！</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/9.gif" style="width:1000px;height:auto" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="手动为nvidia-jetson设备配置yolov8">手动为NVIDIA Jetson设备配置YOLOv8<a href="#手动为nvidia-jetson设备配置yolov8" class="hash-link" aria-label="Direct link to 手动为NVIDIA Jetson设备配置YOLOv8" title="Direct link to 手动为NVIDIA Jetson设备配置YOLOv8">​</a></h2><p>如果之前提到的一键脚本存在一些错误，你可以按照下面的步骤逐个准备Jetson设备以使用YOLOv8。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="安装-ultralytics-包">安装 Ultralytics 包<a href="#安装-ultralytics-包" class="hash-link" aria-label="Direct link to 安装 Ultralytics 包" title="Direct link to 安装 Ultralytics 包">​</a></h3><ul><li><strong>步骤 1.</strong> 访问Jetson设备的终端并安装及升级pip</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt update</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y python3-pip -y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install --upgrade pip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 2.</strong>  安装 Ultralytics 包</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install ultralytics</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 3.</strong>  更新 numpy 至最新版本</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install numpy -U</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 4.</strong> 重启设备</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo reboot</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="卸载-torch-和-torchvision">卸载 Torch 和 Torchvision<a href="#卸载-torch-和-torchvision" class="hash-link" aria-label="Direct link to 卸载 Torch 和 Torchvision" title="Direct link to 卸载 Torch 和 Torchvision">​</a></h3><p>上述的Ultralytics安装过程会安装Torch（PyTorch）和Torchvision。然而，通过pip安装的这两个包与Jetson平台不兼容，因为Jetson平台基于<strong>ARM aarch64</strong>架构。因此，我们需要手动安装预构建的PyTorch pip wheel并从源代码编译/安装Torchvision。</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 uninstall torch torchvision</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="安装-pytorch-和-torchvision">安装 PyTorch 和 Torchvision<a href="#安装-pytorch-和-torchvision" class="hash-link" aria-label="Direct link to 安装 PyTorch 和 Torchvision" title="Direct link to 安装 PyTorch 和 Torchvision">​</a></h3><p>访问 <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson" target="_blank" rel="noopener noreferrer">网页</a> 进入 PyTorch 和 Torchvision 链接.</p><p>以下是JetPack 5.0及以上版本支持的一些版本。</p><p><strong>PyTorch v2.0.0</strong></p><p>支持带有Python 3.8的JetPack 5.1 (L4T R35.2.1) / JetPack 5.1.1 (L4T R35.3.1)</p><p><strong>file_name:</strong> torch-2.0.0+nv23.05-cp38-cp38-linux_aarch64.whl
<strong>URL:</strong> <a href="https://nvidia.box.com/shared/static/i8pukc49h3lhak4kkn67tg9j4goqm0m7.whl" target="_blank" rel="noopener noreferrer">https://nvidia.box.com/shared/static/i8pukc49h3lhak4kkn67tg9j4goqm0m7.whl</a></p><p><strong>PyTorch v1.13.0</strong></p><p>支持带有 Python 3.8的 JetPack 5.0 (L4T R34.1) / JetPack 5.0.2 (L4T R35.1) / JetPack 5.1 (L4T R35.2.1) / JetPack 5.1.1 (L4T R35.3.1) </p><p><strong>file_name:</strong> torch-1.13.0a0+d0d6b1f2.nv22.10-cp38-cp38-linux_aarch64.whl
<strong>URL:</strong> <a href="https://developer.download.nvidia.com/compute/redist/jp/v502/pytorch/torch-1.13.0a0+d0d6b1f2.nv22.10-cp38-cp38-linux_aarch64.whl" target="_blank" rel="noopener noreferrer">https://developer.download.nvidia.com/compute/redist/jp/v502/pytorch/torch-1.13.0a0+d0d6b1f2.nv22.10-cp38-cp38-linux_aarch64.whl</a></p><ul><li><strong>步骤 1.</strong> 根据你的JetPack版本，按照以下格式安装torch。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget &lt;URL&gt; -O &lt;file_name&gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install &lt;file_name&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>例如，我们这里使用的是<strong>JP5.1.1</strong>版本，因此我们选择了<strong>PyTorch v2.0.0</strong>版本。</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt-get install -y libopenblas-base libopenmpi-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://nvidia.box.com/shared/static/i8pukc49h3lhak4kkn67tg9j4goqm0m7.whl -O torch-2.0.0+nv23.05-cp38-cp38-linux_aarch64.whl</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install torch-2.0.0+nv23.05-cp38-cp38-linux_aarch64.whl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 2.</strong> 根据你已经安装的PyTorch版本来安装torchvision。例如，我们选择了PyTorch版本v2.0.0，这就意味着我们需要选择Torchvision版本v0.15.2。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libjpeg-dev zlib1g-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/pytorch/vision torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git checkout v0.15.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 setup.py install --user</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>这里是一个根据你安装的PyTorch版本需要安装的相应torchvision版本的列表：</p><ul><li>PyTorch v2.0.0 - torchvision v0.15</li><li>PyTorch v1.13.0 - torchvision v0.14</li></ul><p>如果你需要更多详细列表, 请访问 <a href="https://github.com/pytorch/vision" target="_blank" rel="noopener noreferrer">此链接</a>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="安装-onnx-和降低-numpy版本">安装 ONNX 和降低 Numpy版本<a href="#安装-onnx-和降低-numpy版本" class="hash-link" aria-label="Direct link to 安装 ONNX 和降低 Numpy版本" title="Direct link to 安装 ONNX 和降低 Numpy版本">​</a></h3><p>这只有在你想要将PyTorch模型转换为TensorRT时才需要。</p><ul><li><strong>步骤 1.</strong> 安装ONNX，这是一个需求。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install onnx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 2.</strong> 降低Numpy版本以避免报错</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install numpy==1.20.3</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="来源">来源<a href="#来源" class="hash-link" aria-label="Direct link to 来源" title="Direct link to 来源">​</a></h2><ul><li><a href="https://docs.ultralytics.com" target="_blank" rel="noopener noreferrer">YOLOv8 documentation</a></li><li><a href="https://docs.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow documentation</a></li><li><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html" target="_blank" rel="noopener noreferrer">TensorRT documentation</a></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="技术支持与项目讨论">技术支持与项目讨论<a href="#技术支持与项目讨论" class="hash-link" aria-label="Direct link to 技术支持与项目讨论" title="Direct link to 技术支持与项目讨论">​</a></h2><p>非常感谢您选择我们的产品！我们提供不同的支持方式，以确保您在使用我们的产品时拥有尽可能流畅的体验。我们提供多种沟通渠道，以适应不同的偏好和需求。</p><div class="button_tech_support_container"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="button_forum"></a><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="button_email"></a></div><div class="button_tech_support_container"><a href="https://discord.gg/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="button_discord"></a><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="button_discussion"></a></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/data-label/">Data Label</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/ai-model-train/">AI model train</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/ai-model-deploy/">AI model deploy</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/yolov-8/">Yolov8</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/zh-CN/Edge/NVIDIA_Jetson/Application/Computer_Vision/YOLOv8-TRT-Jetson.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-07-17T00:00:00.000Z">Jul 17, 2023</time></b> by <b>Lakshantha</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/cn/YOLOv8-DeepStream-TRT-Jetson/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">在NVIDIA Jetson上使用TensorRT和DeepStream SDK部署YOLOv8</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/cn/train_and_deploy_a_custom_classification_model_with_yolov8/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">使用 YOLOv8 训练和部署自定义分类模型</div></a></nav></div><div>Loading Comments...</div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#先决条件" class="table-of-contents__link toc-highlight">先决条件</a></li><li><a href="#刷写-jetpack-到-jetson" class="table-of-contents__link toc-highlight">刷写 JetPack 到 Jetson</a></li><li><a href="#一行代码将-yolov8-部署到-jetson" class="table-of-contents__link toc-highlight">一行代码将 YOLOv8 部署到 Jetson！</a></li><li><a href="#使用预训练模型" class="table-of-contents__link toc-highlight">使用预训练模型</a></li><li><a href="#使用-tensorrt-提高推理速度" class="table-of-contents__link toc-highlight">使用 TensorRT 提高推理速度</a></li><li><a href="#使用自己的ai模型" class="table-of-contents__link toc-highlight">使用自己的AI模型</a><ul><li><a href="#数据收集和标注" class="table-of-contents__link toc-highlight">数据收集和标注</a></li><li><a href="#训练" class="table-of-contents__link toc-highlight">训练</a></li></ul></li><li><a href="#性能基准测试" class="table-of-contents__link toc-highlight">性能基准测试</a><ul><li><a href="#准备" class="table-of-contents__link toc-highlight">准备</a></li><li><a href="#结果" class="table-of-contents__link toc-highlight">结果</a></li></ul></li><li><a href="#额外演示使用yolov8进行运动检测和计数器" class="table-of-contents__link toc-highlight">额外演示：使用YOLOv8进行运动检测和计数器。</a></li><li><a href="#手动为nvidia-jetson设备配置yolov8" class="table-of-contents__link toc-highlight">手动为NVIDIA Jetson设备配置YOLOv8</a><ul><li><a href="#安装-ultralytics-包" class="table-of-contents__link toc-highlight">安装 Ultralytics 包</a></li><li><a href="#卸载-torch-和-torchvision" class="table-of-contents__link toc-highlight">卸载 Torch 和 Torchvision</a></li><li><a href="#安装-pytorch-和-torchvision" class="table-of-contents__link toc-highlight">安装 PyTorch 和 Torchvision</a></li><li><a href="#安装-onnx-和降低-numpy版本" class="table-of-contents__link toc-highlight">安装 ONNX 和降低 Numpy版本</a></li></ul></li><li><a href="#来源" class="table-of-contents__link toc-highlight">来源</a></li><li><a href="#技术支持与项目讨论" class="table-of-contents__link toc-highlight">技术支持与项目讨论</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Navigation</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Getting_Started/">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/Sensor_Network/">Sensor and Sensing</a></li><li class="footer__item"><a class="footer__link-item" href="/Network/">Network</a></li><li class="footer__item"><a class="footer__link-item" href="/Edge_Computing/">Edge Computing</a></li><li class="footer__item"><a class="footer__link-item" href="/Cloud/">Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/Solutions/">Solutions</a></li></ul></div><div class="col footer__col"><div class="footer__title">Ecosystem</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.com/invite/QqMgVwHT3X" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://project.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Project Hub</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/ecosystem/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Partners</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/distributors.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Distributors</a></li></ul></div><div class="col footer__col"><div class="footer__title">Quick Guide</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bazzar</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/HowToGetHelp" target="_blank" rel="noopener noreferrer" class="footer__link-item">How to get help</a></li><li class="footer__item"><a href="https://support.seeedstudio.com/knowledgebase" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQs</a></li><li class="footer__item"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Forum</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/TechnicalSupport" target="_blank" rel="noopener noreferrer" class="footer__link-item">Technical Support</a></li></ul></div><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/about-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">About Seeed</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/join-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Join us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/blog/2020/04/22/seeed-in-the-news/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Press</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Seeed Studio, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.7c471d29.js"></script>
<script src="/assets/js/main.82b0c6ef.js"></script>
</body>
</html>